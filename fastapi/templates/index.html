<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Detection with Face Landmarks</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .container {
            text-align: center;
        }
        video {
            width: 100%;
            max-width: 640px;
            height: auto;
            border: 2px solid #333;
            border-radius: 10px;
        }
        .result {
            margin: 20px 0;
            padding: 15px;
            background: #f0f0f0;
            border-radius: 5px;
            font-size: 18px;
        }
        .controls {
            margin: 20px 0;
        }
        button {
            padding: 10px 20px;
            font-size: 16px;
            background: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        button:hover {
            background: #0056b3;
        }
        button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Real-time Emotion Detection</h1>
        <p>This demo uses MediaPipe Face Mesh to extract facial landmarks in the browser and sends them to your custom emotion detection model.</p>
        
        <div class="controls">
            <button id="startBtn" onclick="startDetection()">Start Detection</button>
            <button id="stopBtn" onclick="stopDetection()" disabled>Stop Detection</button>
        </div>
        
        <video id="videoElement" autoplay muted playsinline></video>
        
        <div id="result" class="result">
            Click "Start Detection" to begin...
        </div>
    </div>

    <script>
        class FaceLandmarkExtractor {
            constructor() {
                this.faceMesh = null;
                this.camera = null;
                this.videoElement = null;
                this.isRunning = false;
            }

            async initialize() {
                // Load MediaPipe Face Mesh
                const script = document.createElement('script');
                script.src = 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4.1633559619/face_mesh.js';
                document.head.appendChild(script);
                
                return new Promise((resolve) => {
                    script.onload = () => {
                        this.faceMesh = new window.FaceMesh({
                            locateFile: (file) => {
                                return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4.1633559619/${file}`;
                            }
                        });

                        this.faceMesh.setOptions({
                            maxNumFaces: 1,
                            refineLandmarks: false,
                            minDetectionConfidence: 0.5,
                            minTrackingConfidence: 0.5
                        });

                        this.faceMesh.onResults(this.onResults.bind(this));
                        resolve();
                    };
                });
            }

            async setupCamera() {
                this.videoElement = document.getElementById('videoElement');
                
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { width: 640, height: 480 }
                });

                this.videoElement.srcObject = stream;
                return new Promise((resolve) => {
                    this.videoElement.onloadedmetadata = () => {
                        resolve(this.videoElement);
                    };
                });
            }

            onResults(results) {
                if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                    const landmarks = results.multiFaceLandmarks[0];
                    
                    // Convert to the format expected by your model (936 coordinates)
                    const coords = [];
                    for (const landmark of landmarks) {
                        coords.push(landmark.x, landmark.y);
                    }
                    
                    // Send to emotion detection (throttled)
                    this.sendToEmotionDetection(coords);
                }
            }

            async sendToEmotionDetection(landmarks) {
                try {
                    const response = await fetch('/detect_emotion', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            landmarks: landmarks
                        })
                    });

                    if (response.ok) {
                        const result = await response.json();
                        this.onEmotionDetected(result);
                    } else {
                        console.error('Error detecting emotion:', response.statusText);
                    }
                } catch (error) {
                    console.error('Error sending landmarks:', error);
                }
            }

            onEmotionDetected(result) {
                const resultDiv = document.getElementById('result');
                resultDiv.innerHTML = `
                    <strong>Emotion:</strong> ${result.emotion}<br>
                    <strong>Confidence:</strong> ${(result.confidence * 100).toFixed(1)}%
                `;
            }

            async start() {
                if (this.isRunning) return;
                
                this.isRunning = true;
                await this.initialize();
                await this.setupCamera();
                
                // Start processing frames
                const processFrame = async () => {
                    if (this.isRunning && this.videoElement.readyState === 4) {
                        await this.faceMesh.send({ image: this.videoElement });
                    }
                    if (this.isRunning) {
                        requestAnimationFrame(processFrame);
                    }
                };
                
                processFrame();
            }

            stop() {
                this.isRunning = false;
                if (this.videoElement && this.videoElement.srcObject) {
                    this.videoElement.srcObject.getTracks().forEach(track => track.stop());
                }
            }
        }

        const detector = new FaceLandmarkExtractor();

        async function startDetection() {
            document.getElementById('startBtn').disabled = true;
            document.getElementById('stopBtn').disabled = false;
            document.getElementById('result').textContent = 'Starting camera...';
            
            try {
                await detector.start();
                document.getElementById('result').textContent = 'Detection started! Look at the camera.';
            } catch (error) {
                document.getElementById('result').textContent = `Error: ${error.message}`;
                document.getElementById('startBtn').disabled = false;
                document.getElementById('stopBtn').disabled = true;
            }
        }

        function stopDetection() {
            detector.stop();
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            document.getElementById('result').textContent = 'Detection stopped.';
        }
    </script>
</body>
</html>

        function stopWebcam() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            
            const video = document.getElementById('video');
            const placeholder = document.getElementById('webcam-placeholder');
            
            video.srcObject = null;
            video.style.display = 'none';
            placeholder.style.display = 'block';
            
            document.getElementById('start-webcam-btn').style.display = 'inline-block';
            document.getElementById('capture-btn').style.display = 'none';
            document.getElementById('stop-webcam-btn').style.display = 'none';
            
            hideResults();
        }

        async function captureAndAnalyze() {
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');
            
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.drawImage(video, 0, 0);
            
            const imageData = canvas.toDataURL('image/jpeg', 0.8);
            
            showLoading();
            hideError();

            try {
                const response = await fetch('/predict-webcam', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ image: imageData })
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }

                const result = await response.json();
                
                if (result.success) {
                    showResults(result.predictions);
                } else {
                    showError(result.error || 'An error occurred while analyzing the image');
                }
            } catch (error) {
                showError('Network error: ' + error.message);
            } finally {
                hideLoading();
            }
        }

        function showResults(predictions) {
            const emotionList = document.getElementById('emotion-list');
            emotionList.innerHTML = '';
            
            predictions.sort((a, b) => b.confidence - a.confidence);
            
            predictions.forEach(pred => {
                const emotionItem = document.createElement('div');
                emotionItem.innerHTML = `${pred.emotion}: ${pred.confidence}%`;
                emotionList.appendChild(emotionItem);
            });
            
            document.getElementById('results').style.display = 'block';
        }

        function showLoading() {
            document.getElementById('loading').style.display = 'block';
        }

        function hideLoading() {
            document.getElementById('loading').style.display = 'none';
        }

        function showError(message) {
            const errorDiv = document.getElementById('error');
            errorDiv.textContent = message;
            errorDiv.style.display = 'block';
        }

        function hideError() {
            document.getElementById('error').style.display = 'none';
        }

        function hideResults() {
            document.getElementById('results').style.display = 'none';
        }
    </script>
</body>
</html>
